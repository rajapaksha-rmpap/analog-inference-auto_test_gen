#!/usr/bin/python
# Copyright (c) 2021, Analog Inference, Inc.

import os
import sys
import shutil
import json
import argparse

from fsimfail import mismatch_check

parser = argparse.ArgumentParser(description="runhwtests and simtop vcd")
parser.add_argument('test_case', help="Enter your test sequence or case as 1st positional argument", nargs='?', default=None)
parser.add_argument('-v', "--vcd", action='store_true', help='run vcd script in simtop', required=False)
parser.add_argument('-string', "--string", type=str, metavar='', help="Test name as a string", required=False)
args = parser.parse_args()

if args.vcd:
    print("Running vcd script!!!")
else:
    print("Running without vcd script!!!") 

stop_on_fail = False

#SHS
proj_path = os.getenv('SW')
testdb_json_file = "testdb.json"
home_dir = os.getcwd()
if proj_path != None:
    desgen_path = proj_path + "/desgen/hwtests"
    testdb_json_file = desgen_path + "/testdb.json"
    home_dir = desgen_path

in_dir = home_dir + "/in/"
ref_dir = home_dir + "/ref/"

cmd = home_dir + "/../desgenhw "

with open(testdb_json_file) as tf:
    testdb = json.load(tf)

num_tests = 0
num_fail = 0
num_enabled = 0
num_user_tests = len(sys.argv) - 1
user_tests_with_specific_string = ""

# user tests could be test sequences or specific tests
user_tests = sys.argv[1:]
#SHS: for regression purposes and only running certain tests with a specific 
#     string in their name such -io
if args.string != None:
    user_tests_with_specific_string = args.string

test_sequences = testdb["test_sequences"]
all_tests = testdb["tests"]
run_sequences = []
test_list = []

user_spec_seq = False
user_spec_tst = False
num_spec_test = 0
asmsys_test = False

#if num_user_tests >= 1 and user_tests_with_specific_string == "":
if args.test_case != None and args.string == None:
    # user has specified one or more test sequence or tests
    # if a sequence is detected, we give it priority

    # check if user specified one or more specific sequences to run
    # collect sequences to run
    for test_sequence in test_sequences:
        if test_sequence["seq_name"] in user_tests:
            run_sequences.append(test_sequence)            
            user_spec_seq = True
            num_spec_test = num_spec_test + 1

    # if no test sequences found, check for individual test cases    
    if not user_spec_seq:
        for test in all_tests:
            if user_spec_tst == True:
                break                         
            for u_test in user_tests:
                if test["name"] == u_test:                   
                    run_sequences.append(test)                    
                    user_spec_tst = True
                    num_spec_test = num_spec_test + 1
                    break

if (args.string != None and args.test_case != None):
    print("Cannot specify -string option with a test case name or sequence")
    exit(1)
elif args.vcd == False and num_user_tests >= 1 and num_user_tests != num_spec_test and user_tests_with_specific_string == "":
    print("One or more specified test/sequence does not exist.")
    exit(1)
elif args.vcd == True and num_user_tests > 1 and num_user_tests-1 != num_spec_test and user_tests_with_specific_string == "":
    print("One or more specified test/sequence does not exist.")
    exit(1)

if len(run_sequences) < 1:
    run_sequences = test_sequences

for test_sequence in run_sequences:
    if user_spec_tst:
        test_list = run_sequences
    elif user_spec_seq:
        test_list = test_sequence["seq_tests"] 

    for test_name in test_list:
        if user_spec_tst:            
            test_name = test_name["name"]
        
        if user_spec_tst and not test_name in user_tests:
            continue

        # SHS: so that the user can specify a string, and only tests that have that
        #      string will be run
        if user_tests_with_specific_string != "":
            if not user_tests_with_specific_string in test_name:
                continue

        sim_json_file = in_dir + test_name + "-sim.json"
        spec_json_file = in_dir + test_name + "-spec.json"

        try:
            with open(sim_json_file) as simf:
                simjson = json.load(simf)
        except IOError:
            print(test_name + " files not found!")
            continue      

        for selected_test in all_tests:
            if selected_test["name"] == test_name:              

                # pick the simulator based on test spec
                if selected_test["asm_sim"] == "asmsyspull_mchip": 
                    asmsys_test = True           
                    scmd = home_dir + "/../../asmsystem/mchip_pull/" + selected_test["asm_sim"] + " "
                elif selected_test["asm_sim"] == "pull": 
                    asmsys_test = True           
                    scmd = home_dir + "/../../asmsystem/pull/" + selected_test["asm_sim"] + " "   
                elif selected_test["asm_sim"] == "push": 
                    asmsys_test = True           
                    scmd = home_dir + "/../../asmsystem/push/" + selected_test["asm_sim"] + " "       
                elif selected_test["asm_sim"] == "asmsyspull_st": 
                    asmsys_test = True           
                    scmd = home_dir + "/../../asmsystem/pull_streaming/" + selected_test["asm_sim"] + " "    
                else:
                    asmsys_test = False
                    scmd = home_dir + "/../../simtop/" + selected_test["asm_sim"] + " "                    

                num_tests += 1
                # clean output artifacts before testing
                os.chdir(home_dir)

                if selected_test["enabled"] == True:
                    print("Running test: " + selected_test["name"])

                    if selected_test["asm_test"] == True:
                        shutil.rmtree(home_dir + "/ASM_test/" + selected_test["name"], True, None)
                        os.mkdir(home_dir + "/ASM_test/" + selected_test["name"])
                        os.chdir(home_dir + "/ASM_test/" + selected_test["name"])
                    else:
                        shutil.rmtree(home_dir + "/results/" + selected_test["name"], True, None)
                        os.mkdir(home_dir + "/results/" + selected_test["name"])
                        os.chdir(home_dir + "/results/" + selected_test["name"])

                    print("Results Directory: " + os.getcwd())

                    num_enabled += 1
                    test_cmd = cmd + "--spec " + in_dir + selected_test["name"] + "-spec.json "\
                                + "--run " + in_dir + selected_test["name"] + "-sim.json"\
                                + " > " + selected_test["name"] + ".log 2>&1"                    
                    res = os.system(test_cmd)

                    if res != 0:
                        num_fail += 1
                        print("Test " + selected_test["name"] + ": Execution Error") 
                        if stop_on_fail == True:
                            exit(1)
                        continue

                    # compare results if execution ok
                    cmp_cmd_1 = "diff map.rpt " + ref_dir + selected_test["name"] + ".rpt"\
                                + " > " + selected_test["name"] + ".rpt.log 2>&1"
                    res1 = os.system(cmp_cmd_1)
                    res5 = 0

                    if "num_auto_images" in simjson:
                        image_count = simjson["num_auto_images"]
                    else:
                        image_count = 1                  

                    for i in range(image_count):
                        
                        if i == 0:
                            cmp_cmd_2 = "diff out.txt " + ref_dir + selected_test["name"] + ".txt"\
                                + " > " + selected_test["name"] + ".txt.log 2>&1"
                            res2 = os.system(cmp_cmd_2)                            
                        else:
                            cmp_cmd_5 = "diff out" + str(i) + ".txt " + ref_dir + selected_test["name"] + "-" + str(i) + ".txt"\
                                + " > " + selected_test["name"] + "-" + str(i) + ".txt.log 2>&1"  
                            res5 = res5 or os.system(cmp_cmd_5)                            

                    if res1 == 0 and res2 == 0 and res5 == 0:
                        if selected_test["asm_test"] == True:
                            print(home_dir)
                            os.chdir(home_dir)
                            simlog = home_dir + "/ASM_test/" + selected_test["name"] + "/"
                            print(selected_test["name"] + ": Level 1 Passed, running " + selected_test["asm_sim"] + "...")                    
                            if selected_test["asm_sim"] == "asmsyspull_mchip":
                                stest_cmd = scmd + simlog + " > " + simlog + "/asmsystem.log" + " 2>&1"                                
                            elif selected_test["asm_sim"] == "asmsyspull_st":
                                stest_cmd = scmd + simlog + " " + str(image_count) + " > " + simlog + "/asmsystem.log" + " 2>&1" 
                            elif selected_test["asm_sim"] == "pull":
                                stest_cmd = scmd + simlog + " > " + simlog + "/asmsystem.log" + " 2>&1" 
                            elif selected_test["asm_sim"] == "push":
                                stest_cmd = scmd + simlog + " > " + simlog + "/asmsystem.log" + " 2>&1"                                        
                            else:
                                stest_cmd = scmd + simlog + " > " + simlog + "simtop.log" + " 2>&1"
                            res3 = os.system(stest_cmd)
                            if res3 == 0:
                                # compare final results
                                cmplog = home_dir + "/ASM_test/" + selected_test["name"] + "/asm_tst_diff.log"
                                file1 = home_dir + "/ASM_test/" + selected_test["name"] + "/out.txt"
                                file2 = home_dir + "/ASM_test/" + selected_test["name"] + "/asm_out.txt"
                                os.system("mv asmlog*.txt" + " " + home_dir + "/ASM_test/" + selected_test["name"] + "/.")

                                # clean the files for comparison
                                os.system("grep -v --text Added " + file1 + " > " + file1 + ".clean")
                                file1 = file1 + ".clean"
                                #print("****** file 1 = " + file1)

                                os.system("grep -v --text Added " + file2 + " > " + file2 + ".clean")
                                file2 = file2 + ".clean"
                                #print("****** file 2 = " + file2)
                                #print("Doing diff: file1[" + file1 + "] file2[" + file2 + "]")

                                cmp_cmd_3 = "diff " + file1 + " " + file2\
                                            + " > " + cmplog + " 2>&1"

                                res4 = os.system(cmp_cmd_3)

                                if res4 == 0:                            
                                    if asmsys_test:
                                        print(selected_test["name"] + ": Asmsystem Passed")
                                    else:
                                        print(selected_test["name"] + ": Simtop passed")
                                else:
                                    if asmsys_test:
                                        print(selected_test["name"] + ": Asmsystem Failed")
                                    else:
                                        print(selected_test["name"] + ": Simtop Failed")
                                    num_fail += 1
                            else:
                                if asmsys_test:
                                        print(selected_test["name"] + ": Asmsystem Failed")
                                else:
                                        print(selected_test["name"] + ": Simtop Failed")                        
                                num_fail += 1
                        else:
                            print(selected_test["name"] + ": Passed")
                    else:
                        print(selected_test["name"] + ": Failed")
                        num_fail += 1
                        
                        # intermediate output checks for each layer if data mismatch in final output of level 1
                        if res2 !=0 or res5 !=0:
                            mismatch_check(selected_test["name"])
                            
                        if stop_on_fail == True:
                            exit(1)
                
                #Moving activity file to simtop and running vcd script for every test case
                activity_file_path = home_dir + "/activity.txt"
                if args.vcd == True:
                    if os.path.isfile(activity_file_path):
                        print("Activity file generated for {}".format(selected_test["name"]))
                        os.system("mv -f {}/activity.txt {}/../../simtop/.".format(home_dir, home_dir))
                        os.chdir("{}/../../simtop".format(home_dir))
                        os.system("python3 vcd.py -i activity.txt -o {}_vcd.txt".format(selected_test["name"]))
                        os.system("mv {}_vcd.txt {}/ASM_test/{}".format(selected_test["name"], home_dir, selected_test["name"]))
                        os.chdir(home_dir)
                    else:
                        print("Activity file has not generated")    

print("Test Run Summary: Total: {0}, Enabled: {1}, Failed: {2}".format(num_tests, num_enabled, num_fail))

os.chdir(home_dir)
exit(0)

